{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ade82a27-714d-4d27-b524-fdca4b0d79fa",
   "metadata": {},
   "source": [
    "# Semantic Search with Approximate Nearest Neighbors and Text Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f38a502-2adb-4c18-abe7-1403532cb7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import apache_beam as beam\n",
    "from apache_beam.transforms import util\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import annoy\n",
    "from sklearn.random_projection import gaussian_random_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6523b5d-3f5a-4a98-8f6f-4af17bd5f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.8.0\n",
      "TF-Hub version: 0.12.0\n",
      "Apache Beam version: 2.39.0\n"
     ]
    }
   ],
   "source": [
    "print('TF version: {}'.format(tf.__version__))\n",
    "print('TF-Hub version: {}'.format(hub.__version__))\n",
    "print('Apache Beam version: {}'.format(beam.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a37936ff-0b36-4616-9979-e3f6a7fa3a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/million-news-headline/text.txt', 'w') as out_file:\n",
    "    with open('../../data/million-news-headline/raw.tsv', 'r') as in_file:\n",
    "        next(in_file)\n",
    "        for line in in_file:\n",
    "            headline = line.split('\\t')[1].strip().strip('\"')\n",
    "            out_file.write(headline+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5180a6-dfd6-4353-ac50-2eb46f1b2179",
   "metadata": {},
   "source": [
    "#### Get News Headline Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8ecb2ac-2ab9-430e-a28b-9634e3b66224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "severe storms forecast for nye in south east queensland\n",
      "snake catcher pleads for people not to kill reptiles\n",
      "south australia prepares for party to welcome new year\n",
      "strikers cool off the heat with big win in adelaide\n",
      "stunning images from the sydney to hobart yacht\n",
      "the ashes smiths warners near miss liven up boxing day test\n",
      "timelapse: brisbanes new year fireworks\n",
      "what 2017 meant to the kids of australia\n",
      "what the papodopoulos meeting may mean for ausus\n",
      "who is george papadopoulos the former trump campaign aide\n"
     ]
    }
   ],
   "source": [
    "!tail ../../data/million-news-headline/text.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "427a1d2d-a543-4905-a1b4-51a3e51b2282",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_fn = None\n",
    "\n",
    "def generate_embeddings(text, module_url, random_projection_matrix=None):\n",
    "  # Beam will run this function in different processes that need to\n",
    "  # import hub and load embed_fn (if not previously loaded)\n",
    "    global embed_fn\n",
    "    if embed_fn is None:\n",
    "        embed_fn = hub.load(module_url)\n",
    "    embedding = embed_fn(text).numpy()\n",
    "    if random_projection_matrix is not None:\n",
    "        embedding = embedding.dot(random_projection_matrix)\n",
    "    return text, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ca990ea-ebf4-499b-b6a6-37ddb70f7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tf_example(entries):\n",
    "    examples = []\n",
    "\n",
    "    text_list, embedding_list = entries\n",
    "    for i in range(len(text_list)):\n",
    "        text = text_list[i]\n",
    "        embedding = embedding_list[i]\n",
    "\n",
    "        features = {\n",
    "            'text': tf.train.Feature(\n",
    "                bytes_list=tf.train.BytesList(value=[text.encode('utf-8')])),\n",
    "            'embedding': tf.train.Feature(\n",
    "                float_list=tf.train.FloatList(value=embedding.tolist()))\n",
    "        }\n",
    "\n",
    "        example = tf.train.Example(\n",
    "            features=tf.train.Features(\n",
    "                feature=features)).SerializeToString(deterministic=True)\n",
    "\n",
    "        examples.append(example)\n",
    "\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53014af7-a115-43a7-b918-e8b2516c7857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_hub2emb(args):\n",
    "    '''Runs the embedding generation pipeline'''\n",
    "\n",
    "    options = beam.options.pipeline_options.PipelineOptions(**args)\n",
    "    args = namedtuple(\"options\", args.keys())(*args.values())\n",
    "\n",
    "    with beam.Pipeline(args.runner, options=options) as pipeline:\n",
    "        (\n",
    "            pipeline\n",
    "            | 'Read sentences from files' >> beam.io.ReadFromText(\n",
    "                file_pattern=args.data_dir)\n",
    "            | 'Batch elements' >> util.BatchElements(\n",
    "                min_batch_size=args.batch_size, max_batch_size=args.batch_size)\n",
    "            | 'Generate embeddings' >> beam.Map(\n",
    "                generate_embeddings, args.module_url, args.random_projection_matrix)\n",
    "            | 'Encode to tf example' >> beam.FlatMap(to_tf_example)\n",
    "            | 'Write to TFRecords files' >> beam.io.WriteToTFRecord(\n",
    "                file_path_prefix='{}/emb'.format(args.output_dir),\n",
    "                file_name_suffix='.tfrecords')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3226a98-659d-4389-9aeb-c19a60783e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_projection_weights(original_dim, projected_dim):\n",
    "    random_projection_matrix = None\n",
    "    random_projection_matrix = gaussian_random_matrix(n_components=projected_dim, n_features=original_dim).T\n",
    "    print(\"A Gaussian random weight matrix was creates with shape of {}\".format(random_projection_matrix.shape))\n",
    "    print('Storing random projection matrix to disk...')\n",
    "    with open('random_projection_matrix', 'wb') as handle:\n",
    "        pickle.dump(random_projection_matrix, \n",
    "                    handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return random_projection_matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
